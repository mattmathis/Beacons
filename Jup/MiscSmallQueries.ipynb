{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables figures to load inline in the browser.\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# Enables figures to load outside of browser.\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def run_query(query, project='mlab-sandbox', **kwargs):\n",
    "    \"\"\" run_query\n",
    "        Yields a DataFrame from a query string\n",
    "        Accepts arbitrary {parameter} substitutions  \n",
    "    \"\"\"\n",
    "    query=query.format(**kwargs)\n",
    "    # print query\n",
    "    client = bigquery.Client(project=project)\n",
    "    job = client.query(query)\n",
    "\n",
    "    results = collections.defaultdict(list)\n",
    "    for row in job.result(timeout=300):\n",
    "        for key in row.keys():\n",
    "            results[key].append(row.get(key))\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The followinq query shows the first 1000 beacons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q=\"\"\"\n",
    "SELECT \n",
    "  clientIP, series_start_asc, series_elapsed_days, series_interval_hours, series_count, series_uploads, series_downloads,  series_end_asc,  series_metro_details\n",
    "FROM `mlab-sandbox.mattmathis.master_annotations`\n",
    "ORDER BY series_start ASC\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "First1k = run_query(Q)\n",
    "print First1k[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEWARE there are OAM addresses in the Master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHeck for Known OAM addresses in master beacons\n",
    "Q=\"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "    `mattmathis.master_annotations`\n",
    "WHERE\n",
    "    clientIP IN ( '45.56.98.222','64.9.225.99','64.9.225.190' )\n",
    "\"\"\"\n",
    "print run_query(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows with unreasonable OctetsOut\n",
    "Roughly 800.  Are they parsing errors or errors in the raw data.\n",
    "Looking through these, many also have unreasonable durations or other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "    test_id as ID,\n",
    "    partition_date as pd,\n",
    "    connection_spec.client_ip as client,\n",
    "    connection_spec.server_hostname as server,\n",
    "    web100_log_entry.snap.HCDataOctetsOut AS out,\n",
    "    web100_log_entry.snap.Duration AS duration\n",
    "FROM `measurement-lab.stable.ndt_all` \n",
    "WHERE\n",
    "    web100_log_entry.snap.HCDataOctetsOut < 0 OR\n",
    "    web100_log_entry.snap.HCDataOctetsOut > 1625000000\n",
    "ORDER BY\n",
    "  out\n",
    "\"\"\"\n",
    "print run_query(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_test\n",
      "0  1527200478\n"
     ]
    }
   ],
   "source": [
    "# WHat was the last test?  How often does it change?\n",
    "Q=\"\"\"\n",
    "SELECT\n",
    "    MAX(web100_log_entry.log_time) AS last_test\n",
    "FROM\n",
    "    `measurement-lab.release.ndt_all`\n",
    "WHERE\n",
    "    partition_date > '2018-05-22'\n",
    "\"\"\"\n",
    "print run_query(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract region to metro map\n",
    "(Actually a dictionary)\n",
    "\n",
    "Manually save the site spreadsheet to /tmp/M-Lab_Sites.csv, run the cell below and paste the output elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "regions = collections.defaultdict(set)\n",
    "transits = collections.defaultdict(set)\n",
    "cities = {}\n",
    "\n",
    "with open('/tmp/M-Lab_Sites.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        site = row['Site'].lower()\n",
    "        metro = site[0:3]\n",
    "        region = row['Region']\n",
    "        transit = row['Transit provider']\n",
    "\n",
    "        regions[region] |= {metro}\n",
    "        transits[transit] |= {site}\n",
    "        cities[metro] = row['City']\n",
    "\n",
    "sregion={}\n",
    "for region in regions:\n",
    "    if region == '':\n",
    "        print \"# Sites with missing region fields\", list(regions[region])\n",
    "        continue\n",
    "    rname = region.replace(' ','_')\n",
    "    sregion[rname] = list(regions[region])\n",
    "print \"contenents =\", sregion\n",
    "\n",
    "stransit={}\n",
    "for transit in transits:\n",
    "    if transit == '':\n",
    "        print \"# Sites with missing transit fields\", list(transits[transit])\n",
    "        continue\n",
    "    stransit[transit] = list(transits[transit])\n",
    "print \"transits =\", stransit\n",
    "\n",
    "print \"cities =\", cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
