{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for inspecting individual beacons\n",
    "\n",
    "See \"Performance Bucket TimeSeries\" and ../ReadMe for more information, including require tools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Install [Jupyter](http://jupyter.org/install)\n",
    "* Install [gcloud SDK](https://cloud.google.com/sdk/downloads)\n",
    "* Install the google-cloud-bigquery package:\n",
    "\n",
    " + `pip install --upgrade google-cloud-bigquery`\n",
    " \n",
    "* Permissions:\n",
    "\n",
    " + Join: `discussion@measurement-lab.net` (See https://www.measurementlab.net/data/docs/bq/quickstart/ )\n",
    " + Authenticate: `gcloud auth application-default login`\n",
    " + Set default project: `gcloud config set project mlab-sandbox`\n",
    " \n",
    "* Start Jupyter\n",
    "\n",
    " + `jupyter notebook`\n",
    " \n",
    "## References\n",
    "\n",
    "* Matplotlib - https://matplotlib.org/contents.html\n",
    "* Pandas - https://pandas.pydata.org/pandas-docs/stable/api.html \n",
    "* BigQuery - https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "import pickle\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global flags\n",
    "\n",
    "Invoke cell individually or reorder them to change defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EndDate = '2018-05-13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip slow/expensive queries\n",
    "DoQueries=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force queries\n",
    "DoQueries=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive figures that pan and zoom\n",
    "interactive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables figures to load inline in the browser and saved (github etc).\n",
    "interactive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable plots for the paper\n",
    "DoPaper = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable plots for the paper\n",
    "DoPaper = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoExp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoExp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default inline\n"
     ]
    }
   ],
   "source": [
    "def setupmatplotlib(force=None):\n",
    "    global interactive\n",
    "    if force == 'inline':\n",
    "        %matplotlib inline\n",
    "        return\n",
    "    elif force == 'interactive':\n",
    "        %matplotlib\n",
    "        return\n",
    "    elif force is not None:\n",
    "        print 'Unknown option, using default'\n",
    "    if interactive:\n",
    "        print 'default interactive'\n",
    "        %matplotlib\n",
    "        return\n",
    "    else:\n",
    "        print 'default inline'\n",
    "        %matplotlib inline\n",
    "        return\n",
    "setupmatplotlib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "# TODO:  COnsider automatically inserting #standardSQL\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def expand_query(query, **kwargs):\n",
    "    \"\"\"expand_query: expans nested {parameter} substitutions.\n",
    "    Stashes forensic output in globals.\n",
    "    \"\"\"\n",
    "    global DebugQuery # For pasting into BQ, after the fact\n",
    "    global NumberedQuery # For grocking BQ error line numbers.\n",
    "    global DefaultArgs # To ignore some \n",
    "\n",
    "    # Only allow argument substitution 4 levels deep, because\n",
    "    # accidental infinite recursion risks crashing the notebook.\n",
    "    args = DefaultArgs.copy()\n",
    "    args.update(kwargs)\n",
    "    query=query.format(**args)\n",
    "    query=query.format(**args)\n",
    "    query=query.format(**args)\n",
    "    query=query.format(**args)\n",
    "    if '{' in query:\n",
    "        raise \"Unexpanded substitutions\"\n",
    "    \n",
    "    # Leave crumbs if we need a postmortem\n",
    "    DebugQuery = query\n",
    "    NumberedQuery = \"\"\n",
    "    for i, l in enumerate(query.split('\\n')):\n",
    "          NumberedQuery += \"%3d %s\\n\"%(i, l)\n",
    "\n",
    "    return query\n",
    "\n",
    "def run_query(query, project='mlab-sandbox', otherindex=None, timeindex='partition_date', **kwargs):\n",
    "    \"\"\" run_query\n",
    "        Accepts nested {parameter} substitutions.\n",
    "        \n",
    "        Stashes forensic output in globals.\n",
    "    \"\"\"\n",
    "    global NumberedQuery\n",
    "    query=expand_query(query,  **kwargs)\n",
    "\n",
    "    # do the work\n",
    "    client = bigquery.Client(project=project)\n",
    "    job = client.query(query)  # All errors are delayed\n",
    "\n",
    "    # Marshal the results, catching async errors\n",
    "    try:\n",
    "        results = collections.defaultdict(list)\n",
    "        for row in job.result(timeout=300):\n",
    "            for key in row.keys():\n",
    "                results[key].append(row.get(key)) \n",
    "    except:\n",
    "        print NumberedQuery\n",
    "        raise\n",
    "\n",
    "    if otherindex:\n",
    "        return pd.DataFrame(results, index=results[otherindex])\n",
    "    # Default is timeindex='partition_date', but 'test_time' is common\n",
    "    if timeindex == 'test_time':\n",
    "        print \"Index by test_time\"\n",
    "        return pd.DataFrame(results,\n",
    "                            index=pd.DatetimeIndex(results[timeindex]*1000000000))\n",
    "\n",
    "    if timeindex:\n",
    "        return pd.DataFrame(results, index=pd.DatetimeIndex(results[timeindex]))\n",
    "    # set timeindex=None to force a raw DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def write_query_table(query, otable,\n",
    "                      project='mlab-sandbox', dataset_id='mattmathis',\n",
    "                      **kwargs):\n",
    "    \"\"\" write_query_table\n",
    "        Accepts nested {parameter} substitutions.\n",
    "        \n",
    "        Stashes forensic output in globals.\n",
    "    \"\"\"\n",
    "    global NumberedQuery\n",
    "    query=expand_query(query,  **kwargs)\n",
    "\n",
    "    # do the work\n",
    "    client = bigquery.Client(project=project)\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    table_ref = client.dataset(dataset_id).table(otable)\n",
    "    job_config.destination = table_ref\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "    # Marshal the results, catching async errors\n",
    "    try:\n",
    "        res = job.result()  # Get the first row to make sure it starts\n",
    "        while not job.done():\n",
    "            print 'tick'\n",
    "            time.sleep(5)\n",
    "        assert job.state == 'DONE'\n",
    "    except:\n",
    "        print \"Query Errored\"\n",
    "        print NumberedQuery\n",
    "        raise\n",
    "    print \"Query completed\"\n",
    "    return\n",
    "# Not tested, can read a table with\n",
    "#    iterator = client.list_rows(\n",
    "#        table_ref, selected_fields=[bigquery.SchemaField('my_col', 'INT64')]) \n",
    "    \n",
    "if False:\n",
    "    testQ=\"\"\"\n",
    "    SELECT *\n",
    "    FROM `mattmathis.new_master_annotations`\n",
    "    \"\"\"\n",
    "    write_query_table(testQ, otable='test_results2')\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def unlog(x, pos):\n",
    "    v = math.pow(10, x)\n",
    "    frac, whole = math.modf(v)\n",
    "    if frac > 0:\n",
    "        return '%.1f' % v\n",
    "    else:\n",
    "        return '%d' % whole\n",
    "\n",
    "logFormatter = matplotlib.ticker.FuncFormatter(unlog)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Automaticly save or restor pickle data\n",
    "def AutoPickle(data, name, save=True):\n",
    "    fname = name+'.pickle'\n",
    "    try:\n",
    "        if len(data) <2:\n",
    "            raise \"Not Valid\"\n",
    "        if save:\n",
    "            print \"Saving Data\"\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        else:\n",
    "            print \"Data seems valid, but save != True\"\n",
    "        return(data)\n",
    "    except:\n",
    "        print \"Loading prior data\"\n",
    "        with open(fname, 'rb') as f:\n",
    "            return(pickle.load(f))\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query templates for most of the plots below\n",
    "Unidirectional with selected percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# All of these queries yield timeseries of multidimensional histograms of 'value'\n",
    "\n",
    "# Query the list of beacons\n",
    "BeaconQ =\"\"\"\n",
    "SELECT\n",
    "  clientIP {beacon_fields}\n",
    "FROM\n",
    "  `mattmathis.new_master_annotations`\n",
    "WHERE\n",
    "  clientIP NOT IN (\n",
    "    '45.56.98.222',\n",
    "    '64.9.225.99',\n",
    "    '64.9.225.190' ) # exclude eb, etc\n",
    "    {beacon_where}\n",
    "\"\"\"\n",
    "\n",
    "# Query relevant fields of the beacons of interest\n",
    "# This yields one row per test\n",
    "# with download rate (Mb/s) in column 'value'\n",
    "DownloadQ=\"\"\"\n",
    "SELECT\n",
    "  partition_date,\n",
    "  web100_log_entry.connection_spec.remote_ip AS clientIP,\n",
    "  connection_spec.data_direction AS direction,\n",
    "  web100_log_entry.connection_spec.local_ip AS local_ip,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 5),\n",
    "         \"UNK\") AS server_site,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 3),\n",
    "         \"UNK\") AS server_metro,\n",
    "  web100_log_entry.log_time AS test_time,\n",
    "  web100_log_entry.snap.duration AS duration,\n",
    "  web100_log_entry.snap.HCDataOctetsOut AS bytes_transfered,\n",
    "  {more_data}\n",
    "  SAFE_DIVIDE(web100_log_entry.snap.HCDataOctetsOut, web100_log_entry.snap.duration) * 8 AS value\n",
    "FROM\n",
    "  `measurement-lab.release.ndt_all`\n",
    "WHERE\n",
    "  connection_spec.data_direction = 1\n",
    "  AND web100_log_entry.snap.duration > 10000\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut > 0\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut < 1625000000\n",
    "  {data_where}\n",
    "  AND partition_date <= '{enddate}' \n",
    "\"\"\"\n",
    "\n",
    "# Query relevant fields of the beacons of interest\n",
    "# This yields one row per test\n",
    "# with upload rate (Mb/s) in column 'value'\n",
    "UploadQ=\"\"\"\n",
    "SELECT\n",
    "  partition_date,\n",
    "  web100_log_entry.connection_spec.remote_ip AS clientIP,\n",
    "  connection_spec.data_direction AS direction,\n",
    "  web100_log_entry.connection_spec.local_ip AS local_ip,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 5),\n",
    "         \"UNK\") AS server_site,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 3),\n",
    "         \"UNK\") AS server_metro,\n",
    "  web100_log_entry.log_time AS test_time,\n",
    "  web100_log_entry.snap.duration AS duration,\n",
    "  web100_log_entry.snap.HCDataOctetsIn AS bytes_transfered,\n",
    "  {more_data}\n",
    "  SAFE_DIVIDE(web100_log_entry.snap.HCDataOctetsIn, web100_log_entry.snap.duration) * 8 AS value\n",
    "FROM\n",
    "  `measurement-lab.release.ndt_all`\n",
    "WHERE\n",
    "  connection_spec.data_direction = 0\n",
    "  AND web100_log_entry.snap.duration > 10000\n",
    "  AND web100_log_entry.snap.HCDataOctetsIn > 0\n",
    "  AND web100_log_entry.snap.HCDataOctetsIn < 1625000000\n",
    "  {data_where}\n",
    "  AND partition_date <= '{enddate}' \n",
    "\"\"\"\n",
    "\n",
    "# Query relevant fields of the beacons of interest\n",
    "# This yields one row per test\n",
    "# with RTT in column 'value'\n",
    "RTTQ=\"\"\"\n",
    "SELECT\n",
    "  partition_date,\n",
    "  web100_log_entry.connection_spec.remote_ip AS clientIP,\n",
    "  connection_spec.data_direction AS direction,\n",
    "  web100_log_entry.connection_spec.local_ip AS local_ip,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 5),\n",
    "         \"UNK\") AS server_site,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 3),\n",
    "         \"UNK\") AS server_metro,\n",
    "  web100_log_entry.log_time AS test_time,\n",
    "  web100_log_entry.snap.duration AS duration,\n",
    "  web100_log_entry.snap.HCDataOctetsOut AS bytes_transfered, \n",
    "  SAFE_DIVIDE(web100_log_entry.snap.SumRTT, web100_log_entry.snap.CountRTT) AS value\n",
    "FROM\n",
    "  `measurement-lab.release.ndt_all`\n",
    "WHERE\n",
    "  connection_spec.data_direction = 1\n",
    "  AND web100_log_entry.snap.duration > 10000\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut > 0\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut < 1625000000\n",
    "  {data_where}\n",
    "  AND partition_date <= '{enddate}' \n",
    "\"\"\"\n",
    "\n",
    "# Query relevant fields of the beacons of interest\n",
    "# This yields one row per test\n",
    "# with MinRTT in column 'value'\n",
    "MinRTTQ=\"\"\"\n",
    "SELECT\n",
    "  partition_date,\n",
    "  web100_log_entry.connection_spec.remote_ip AS clientIP,\n",
    "  connection_spec.data_direction AS direction,\n",
    "  web100_log_entry.connection_spec.local_ip AS local_ip,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 5),\n",
    "         \"UNK\") AS server_site,\n",
    "  IFNULL(SUBSTR(connection_spec.server_hostname, -25, 3),\n",
    "         \"UNK\") AS server_metro,\n",
    "  web100_log_entry.log_time AS test_time,\n",
    "  web100_log_entry.snap.duration AS duration,\n",
    "  web100_log_entry.snap.HCDataOctetsOut AS bytes_transfered, \n",
    "  web100_log_entry.snap.MinRTT AS value\n",
    "FROM\n",
    "  `measurement-lab.release.ndt_all`\n",
    "WHERE\n",
    "  connection_spec.data_direction = 1\n",
    "  AND web100_log_entry.snap.duration > 10000\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut > 0\n",
    "  AND web100_log_entry.snap.HCDataOctetsOut < 1625000000\n",
    "  {data_where}\n",
    "  AND partition_date <= '{enddate}' \n",
    "\"\"\"\n",
    "\n",
    "# Joinclause\n",
    "joinQ = \"\"\"\n",
    "    SELECT *\n",
    "    FROM ( {data} )\n",
    "    INNER JOIN ( {beacons} )\n",
    "    USING ( clientIP )\n",
    "\"\"\"\n",
    "\n",
    "# Aggregate test statistics by partition_date and server_site\n",
    "mainQ=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  UNIX_DATE(partition_date) * 86400 AS partition_time,\n",
    "  partition_date,\n",
    "  server_site,\n",
    "  ANY_VALUE(server_metro) AS server_metro,\n",
    "  COUNTIF(value < 1.0) AS LT001,\n",
    "  COUNTIF(value < 2.0) AS LT002,\n",
    "  COUNTIF(value < 4.0) AS LT004,\n",
    "  COUNTIF(value < 8.0) AS LT008,\n",
    "  COUNTIF(value < 16.0) AS LT016,\n",
    "  COUNTIF(value < 32.0) AS LT032,\n",
    "  COUNTIF(value < 64.0) AS LT064,\n",
    "  COUNTIF(value < 128.0) AS LT128,\n",
    "  COUNTIF(value < 256.0) AS LT256,\n",
    "  COUNTIF(value < 512.0) AS LT512,\n",
    "  COUNT(*) AS count\n",
    "FROM ( {joinclause} )\n",
    "GROUP BY\n",
    "  partition_date,\n",
    "  server_site\n",
    "ORDER BY\n",
    "  partition_date\n",
    "\"\"\"\n",
    "\n",
    "global EndDate # pervent irrelevant changes\n",
    "# Default values for optional parameters\n",
    "DefaultArgs = {\n",
    "    'beacons':BeaconQ,\n",
    "    'beacon_fields':'',\n",
    "    'beacon_where':'',\n",
    "    'data':DownloadQ,\n",
    "    'more_data':'',\n",
    "    'data_where':'',\n",
    "    'enddate':EndDate,\n",
    "    'joinclause':joinQ\n",
    "}\n",
    "\n",
    "# Useful debugging queries\n",
    "CountQ=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "    count(*) AS count\n",
    "FROM ( {counted} )\n",
    "\"\"\"\n",
    "\n",
    "LimitQ=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "    *\n",
    "FROM ( {counted} ) LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count\n",
      "0  1555329\n"
     ]
    }
   ],
   "source": [
    "# Confirm that BQ credentials are working\n",
    "# Count Master Beacons, Should be 1.55M\n",
    "if True:\n",
    "        print run_query(CountQ, counted=BeaconQ, timeindex=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Fleet Information\n",
    "\n",
    "The first cell below was generated by MiscSmallQueries, which extracts the data from the sites spreadsheet.\n",
    "\n",
    "The second cell below was manaully generated to help tell some stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sites with missing region fields ['']\n",
    "contenents = {'Europe': ['vie', 'bcn', 'ham', 'trn', 'svg', 'dub', 'lis', 'fra', 'ath', 'beg', 'lba', 'prg', 'par', 'lhr', 'lca', 'mil', 'ams', 'lju', 'bru', 'arn', 'mad'], 'Oceania': ['wlg', 'syd', 'akl'], 'South_America': ['fln', 'bog'], 'Africa': ['acc', 'jnb', 'tnr', 'nbo', 'tun', 'los', 'mpm'], 'Asia': ['tpe', 'mnl', 'hnd', 'bkk', 'sin', 'bom'], 'North_America': ['yqm', 'den', 'yvr', 'mia', 'iad', 'atl', 'lga', 'nuq', 'ywg', 'yyc', 'lax', 'yul', 'sea', 'sjc', 'ord', 'yyz', 'dfw']}\n",
    "# Sites with missing transit fields ['', 'lga0t', 'iad0t', 'iad1t']\n",
    "transits = {'Serbian Open eXchange': ['beg01'], 'Level 3': ['fra04', 'mad02'], 'go6': ['lju01'], 'Tata': ['bom02', 'mia03', 'ord03', 'lax02', 'sin01', 'nuq04', 'lga03', 'dfw02', 'atl03', 'sea02', 'iad03'], 'Internap': ['atl06', 'ams07', 'sjc01', 'lga07', 'dfw06', 'sea06'], 'Hurricane Electric': ['yul02', 'yul01', 'yyz02', 'yyc01', 'yyz01', 'yvr01', 'yyc02', 'yqm01', 'ywg01'], 'PHOpenIX': ['mnl01'], 'Biglobe': ['hnd02'], 'ISC': ['nuq02'], 'Vodafone': ['ams05', 'arn02', 'lis02', 'bru01', 'mil05', 'lhr04', 'par05', 'prg05', 'fra03'], 'Ghana IXP': ['acc02', 'acc01'], 'CAT Telecom': ['bkk01'], 'Victoria University of Wellington': ['wlg01'], 'AARNET': ['syd01'], 'Telia': ['mad03', 'arn01', 'arn04', 'lhr02', 'ams03', 'par01', 'fra01', 'mil02', 'ham01', 'prg03', 'bru03', 'par03'], 'RNP (ASN 1916) and FAPESC (ASN 52950).': ['fln01'], 'Tinet': ['mad01', 'mil01'], 'Altibox': ['svg01'], 'Zayo': ['dfw05', 'mia05', 'ord05', 'lga06', 'den04', 'nuq06', 'lax05'], 'Vocus': ['syd02'], 'Leaseweb': ['ams06'], 'XO': ['dfw04', 'atl05', 'den03', 'nuq05', 'sea05', 'iad01'], 'WIDE': ['hnd01'], 'REANNZ': ['akl01', 'wlg02'], 'CyNet': ['lca01'], 'Ubuntunet': ['nbo01'], 'RTR': ['vie01'], 'Nigeria IXP': ['los01'], 'Cogent': ['ord02', 'mia02', 'dfw01', 'atl02', 'sea01', 'nuq03', 'lax01', 'iad02', 'lga02'], 'CATNIX / Orange': ['bcn01'], 'GTT': ['ams04', 'lhr03', 'mia04', 'prg04', 'arn05', 'mad04', 'par04', 'lax03', 'ord04', 'fra02', 'sea03', 'atl04', 'mil03', 'lga04', 'den01', 'iad04', 'bru04'], 'Airtel': ['bom01'], 'aql': ['lba01'], 'National Chi Nan University': ['tpe01'], 'ATI': ['tun01'], 'Voxel': ['lga01'], 'Google': ['nuq01'], 'Internap / Voxel': ['ams02'], 'Telecom Malagasy': ['tnr01'], 'Topix': ['trn01'], 'GRNET': ['ath01', 'ath02', 'ath03'], 'Tenet': ['jnb01'], 'HEanet': ['dub01'], 'Level3': ['lhr01', 'arn03', 'ams01', 'lhr05', 'mia01', 'lga05', 'lga1t', 'mil04', 'prg01', 'lax04', 'lis01', 'par02', 'atl01', 'bru02', 'dfw03', 'prg02', 'den02', 'sea04', 'iad05', 'ord01'], 'Telefonica': ['bog01'], 'Morenet': ['mpm01']}\n",
    "cities = {'': '', 'prg': 'Prague', 'yyc': 'Calgary', 'vie': 'Vienna', 'bru': 'Brussells', 'nuq': 'San Jose', 'lba': 'Leeds', 'jnb': 'Johannesburg', 'yul': 'Montreal', 'mnl': 'Quezon City', 'sea': 'Seattle', 'ord': 'Chicago', 'arn': 'Stockholm', 'tpe': 'Taipei', 'fra': 'Frankfurt', 'ham': 'Hamburg', 'yvr': 'Vancouver', 'mia': 'Miami', 'iad': 'Washington', 'dfw': 'Dallas', 'los': 'Lagos', 'lis': 'Lisbon', 'sjc': 'San Jose', 'sin': 'Changi', 'lhr': 'London', 'yqm': 'Moncton', 'lga': 'New York', 'syd': 'Sydney', 'akl': 'Auckland', 'par': 'Paris', 'bkk': 'Bangkok', 'mpm': 'Maputo', 'lax': 'Los Angeles', 'mad': 'Madrid', 'tun': 'Tunis', 'lca': 'Nicosia', 'ams': 'Amsterdam', 'yyz': 'Toronto', 'mil': 'Milan', 'acc': 'Accra', 'bcn': 'Barcelona', 'hnd': 'Tokyo', 'tnr': 'Antananarivo', 'svg': 'Sola', 'atl': 'Atlanta', 'trn': 'Turin', 'beg': 'Belgrade', 'ath': 'Athens', 'ywg': 'Winnipeg', 'bom': 'Mumbai', 'den': 'Denver', 'fln': 'Florian\\xc3\\xb3polis', 'nbo': 'Nairobi', 'wlg': 'Wellington', 'lju': 'Ljubljana', 'dub': 'Dublin', 'bog': 'Bogota'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual metro sets\n",
    "USAmetros = ['lga', 'den', 'iad', 'dfw', 'ord', 'lax', 'sea', 'nuq']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default beacon timeseries plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Base series plotting code\n",
    "def new_plot_beacon_rates(pdata, ofile=None, title=None, ztime=None, xlim=None, figsize=(16, 20)):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=figsize)\n",
    "   \n",
    "    ax = axes # was for ax in axes:\n",
    "\n",
    "    # make it pretty\n",
    "    ax.xaxis.set_major_locator(matplotlib.dates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(matplotlib.dates.MonthLocator())\n",
    "    if ofile:\n",
    "        ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "        ax.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter(''))\n",
    "    else:\n",
    "        ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y   '))\n",
    "        #  ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%m'))\n",
    "        \n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    # print list(pdata), list(pdata['test_time'])\n",
    "    rate = pdata['rate']\n",
    "    if ztime:\n",
    "        hour = (pdata['test_time'] % 86400) / 3600.0\n",
    "        ax.plot(rate[hour > ztime], marker='x', linestyle='None', label='')\n",
    "        ax.plot(rate[hour < ztime], marker='+', linestyle='None', label='')\n",
    "    else:\n",
    "        ax.plot(rate, marker='.', linestyle='None', label='')\n",
    "\n",
    "    # if\n",
    "    if title and not ofile:\n",
    "        fig.suptitle(title, y='0.97', fontsize=14)\n",
    "    if ofile:\n",
    "        fig.savefig(ofile, dpi=100)\n",
    "    plt.show()\n",
    "    # plt.close\n",
    "# tester needed\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing area\n",
    "Paste experimental query and plotting below.  When done, move to the proper section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE LOG for experimental  (this duplicates another cell)\n",
    "\n",
    "# Query beacons of interest\n",
    "# Time series of single beacons, for illustration \n",
    "\n",
    "# beacon slectors\n",
    "first1000beacons=\"\"\"\n",
    "  ORDER BY series_start ASC LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "greedybeacons=\"\"\"\n",
    "  ORDER BY series_download_bytes DESC LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "longestbeacons=\"\"\"\n",
    "    ORDER BY series_elapsed_days DESC LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "selectedBeaconQ =\"\"\"\n",
    "SELECT\n",
    "  clientIP {beacon_fields}\n",
    "FROM\n",
    "  `mattmathis.new_master_annotations`\n",
    "WHERE\n",
    "  clientIP IN ( {roguesgallery} )\n",
    "\"\"\"\n",
    "\n",
    "beacon_fields=\", series_start, series_start_asc, series_count, series_download_bytes, series_elapsed_days\"\n",
    "\n",
    "seriesQ=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  UNIX_DATE(partition_date) * 86400 AS partition_time,\n",
    "  partition_date,\n",
    "  server_site,\n",
    "  server_metro,\n",
    "  clientIP,\n",
    "  test_time,\n",
    "  duration,\n",
    "  bytes_transfered,\n",
    "  value AS rate\n",
    "  {beacon_fields}\n",
    "FROM ( {joinclause} )\n",
    "ORDER BY test_time ASC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 823881\n"
     ]
    }
   ],
   "source": [
    "# Focus on Interconnection Beacons\n",
    "# Running to lga between 2013-01-01 and 2014-08-01\\\n",
    "# To selected access ISPs\n",
    "if True:\n",
    "#    bw = 'ORDER BY series_start ASC LIMIT 10'\n",
    "    beacon_where = \"\"\"\n",
    "        AND series_start_asc < '2013-01-01'\n",
    "        AND series_end_asc > '2014-08-01'\n",
    "#        AND REGEXP_CONTAINS(clientIP, '^24.')\n",
    "#        ORDER BY series_count DESC\n",
    "#        LIMIT 10\n",
    "        \"\"\"\n",
    "    data_where = \"\"\"\n",
    "        AND SUBSTR(connection_spec.server_hostname, -25, 3) in ( {metros} )\n",
    "        \"\"\"\n",
    "    tmpargs = {\n",
    "        'data':DownloadQ,\n",
    "        'beacon_fields':beacon_fields,\n",
    "        'beacon_where':beacon_where,\n",
    "        'data_where':data_where,\n",
    "        'metros':\" 'lga' \"\n",
    "    }\n",
    "    InterconnectionBeacons = run_query(seriesQ, timeindex=None, **tmpargs)\n",
    "    InterconnectionBeacons.index = pd.DatetimeIndex(\n",
    "        InterconnectionBeacons['test_time']*1000000000) # NB: test_time\n",
    "print 'Done', len(InterconnectionBeacons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print InterconnectionBeacons[0:2]\n",
    "# print NumberedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dive into Interconnection study beacons\n",
    "if True:\n",
    "    setupmatplotlib('inline')\n",
    "    xlim=pd.DatetimeIndex(['2013-01-01','2014-08-01'])\n",
    "    # print xlim\n",
    "    tmp = pd.DataFrame(InterconnectionBeacons, copy=True)\n",
    "    clients = set(tmp['clientIP'])\n",
    "    print \"Clients: \", len(clients)\n",
    "    \n",
    "    ptmp = tmp.pivot_table(index=tmp.index, columns='clientIP',\n",
    "                           values=['rate','test_time'])\n",
    "    #    print clients\n",
    "    # print tmp[0:3]\n",
    "    print ptmp                                                                   \n",
    "\n",
    "    for c, i in zip(clients, range(len(clients))):\n",
    "        if i > 10:\n",
    "            break\n",
    "        print 'lga beacon:', c\n",
    "        new_plot_beacon_rates(tmp[tmp['clientIP']==c], xlim=xlim,\n",
    "                              title='Lga beacon: '+c, ztime=12.0,\n",
    "                              figsize=(16, 3))\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for  genericly interesting  beacons\n",
    "(High rate, frequent or early tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query and Display the 100 greedyest beacons\n",
    "if DoQueries:\n",
    "    GreedyBeacons = run_query(seriesQ,\n",
    "                             beacon_fields=beacon_fields, beacon_where=greedybeacons)\n",
    "    GreedyBeacons.index=pd.DatetimeIndex(GreedyBeacons['test_time']*1000000000)\n",
    "    print GreedyBeacons[0:3]\n",
    "    print 'Query Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Force inline because interactive opens seperate windows for each\n",
    "    %matplotlib inline\n",
    "    tmp = pd.DataFrame(GreedyBeacons, copy=True)\n",
    "    \n",
    "    pdata = tmp.pivot_table(index=tmp.index, columns='clientIP', values='rate')\n",
    "    clients=list(pdata)\n",
    "    for c, n in zip(clients, range(len(clients))):\n",
    "        t = GreedyBeacons[GreedyBeacons['clientIP']== c]\n",
    "        print \"   '%s', # Greedy %d\"%(c, n)\n",
    "        new_plot_beacon_rates(t, title=\"Client \"+c, figsize=(16, 3))\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 1000 Beacons\n",
    "if DoQueries:\n",
    "    First1000Beacons = run_query(seriesQ,\n",
    "                             beacon_fields=beacon_fields, beacon_where=first1000beacons)\n",
    "    First1000Beacons.index=pd.DatetimeIndex(First1000Beacons['test_time']*1000000000)\n",
    "if True:\n",
    "    # Force inline because interactive opens seperate windows for each\n",
    "    %matplotlib inline\n",
    "    # Force copying to prevent corrupting raw_data[] when re-executing bad code\n",
    "    pdata = First1000Beacons.pivot_table(index=tmp.index, columns='clientIP', values='rate')\n",
    "    clients=list(pdata)\n",
    "\n",
    "    for c, n in zip(clients, range(len(clients))):\n",
    "        print \"   '%s', # First %d\"%(c, n)\n",
    "        plot_beacon_rates(First1000Beacons[c], title=\"Client \"+c, figsize=(16, 3))\n",
    "    print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 100 longest beacons\n",
    "if DoQueries:\n",
    "    LongestBeacons =  run_query(seriesQ, timeindex='test_time',\n",
    "                             beacon_fields=beacon_fields, beacon_where=longestbeacons)\n",
    "if True:\n",
    "    # Force inline because interactive opens seperate windows for each\n",
    "    %matplotlib inline\n",
    "    tmp = pd.DataFrame(LongestBeacons, copy=True)\n",
    "    tmp.index = pd.DatetimeIndex(tmp['test_time']*1000000000)\n",
    "    pdata = tmp.pivot_table(index=tmp.index, columns='clientIP', values='rate')\n",
    "    print len(list(pdata))\n",
    "    for c, n in zip(list(pdata), range(len(pdata))):\n",
    "        print \"   '%s', # Longest %d\"%(c, n)\n",
    "        plot_beacon_rates(pdata, title=\"Client \"+c, clients=[c], figsize=(16, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if True:\n",
    "    # Force inline because interactive opens seperate windows for each\n",
    "    setupmatplotlib('inline')\n",
    "    \n",
    "    pdata = InterconnectionBeacons.pivot_table(\n",
    "                            columns='clientIP', values=['test_time', 'rate' ])\n",
    "    clients=list(pdata['test_time'])\n",
    "    # clients=['24.113.136.215']\n",
    "    print clients\n",
    "    for c, n in zip(clients, range(len(clients))):\n",
    "        print \"   '%s', # First %d\"%(c, n)\n",
    "        tmp = InterconnectionBeacons[InterconnectionBeacons['clientIP'] == c]\n",
    "        # print tmp\n",
    "        new_plot_beacon_rates(tmp, title=\"Client \"+c, figsize=(16, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SAVE slice on arbitarry predicates\n",
    "# debugging code\n",
    "# Test queries\n",
    "\n",
    "predicate = 'REGEXP_CONTAINS(ClientType, \"BT\")'  # not it   \n",
    "predicate = 'connection_spec.websockets IS TRUE' # Big shift 2017-05-01\n",
    "if False:\n",
    "    args = {\n",
    "        'clist':['North_America'],\n",
    "        'predicate':predicate,\n",
    "#        'cohort':'2010-06-01',\n",
    "#        'coend':'2018-01-01',\n",
    "        'more_data':'connection_spec.websockets AS websockets, '\n",
    "    }\n",
    "    comparison = {\n",
    "        'NA_all':query_global_cohort(pmode=0, **args)['North_America'],\n",
    "        'NA_withoutPred':query_global_cohort(pmode=-1, **args)['North_America'],\n",
    "        'NA_OnlyPred':query_global_cohort(pmode=-2, **args)['North_America']}\n",
    "\n",
    "import time\n",
    "if DoExp:\n",
    "    setupmatplotlib('interactive')\n",
    "    time.sleep(1)\n",
    "    plot_geo_rates(comparison)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging code\n",
    "# Test queries\n",
    "Beacon Timeseries\n",
    "predicate = 'REGEXP_CONTAINS(ClientType, \"BT\")'  # not it   \n",
    "predicate = 'connection_spec.websockets IS TRUE' # Big shift 2017-05-01\n",
    "if False:\n",
    "    args = {\n",
    "        'clist':['North_America'],\n",
    "        'predicate':predicate,\n",
    "#        'cohort':'2010-06-01',\n",
    "#        'coend':'2018-01-01',\n",
    "        'more_data':'connection_spec.websockets AS websockets, '\n",
    "    }\n",
    "    comparison = {\n",
    "        'NA_all':query_global_cohort(pmode=0, **args)['North_America'],\n",
    "        'NA_withoutPred':query_global_cohort(pmode=-1, **args)['North_America'],\n",
    "        'NA_OnlyPred':query_global_cohort(pmode=-2, **args)['North_America']}\n",
    "\n",
    "if DoExp:\n",
    "    setupmatplotlib('interactive')\n",
    "    plot_geo_rates(comparison)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series of individual beacons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed plot of manually slected beacons\n",
    "# Note that thispPredates new master beacons, and many are excluded now\n",
    "roguesgallery = [\n",
    " '144.130.155.1', # Greedy 23 - Strong ~2 MB/s Max + outliers UP\n",
    " '163.7.137.201', # Grenew_plot_beacon_ratesedy 25  ~ 850 M/b max but only 2 days\n",
    " '163.7.137.243', # Greedy 26 -  850 M/b max, 5 days\n",
    " '195.143.162.141', # Greedy 35\t- Varying flattop (w/ outliers)\n",
    " '204.246.122.65', # Greedy 42 - Varying flattop (w/ outliers) ~ 3 years\n",
    " '208.77.130.154', # Greedy 48 - stripes\n",
    " '23.228.128.99', # Greedy 52 - stripes\n",
    " '45.79.140.244', # Greedy 56 - 850 for ~ 1 day, then 400 Mb/s\n",
    " '45.79.155.9', # Greedy 57 - Man test at low rates, two spikes one to 800+\n",
    " '77.95.64.13', # Greedy 90 - several days at ~700 Mb/s, downward shift\n",
    " '121.54.32.106', # Longest 7 (and many like it) thin viel w/ gaps July 2010, 2012 2016-2017, upward slope\n",
    " '217.72.93.226', # Longest 64 - long staircase\n",
    " '84.1.111.194', # Longest 93 - long staircase\n",
    " '93.99.142.1', # Longest 99 - 3 rate steps but decreasing test volumes\n",
    " '121.54.32.102', # First 42 - Another BT?\n",
    " # (Through)\n",
    " '121.54.32.108', # First 46\n",
    " '84.235.73.18', # First 819 - NAT!  Very uniform noisy mostly under 2 MB/s\n",
    " '84.235.73.19', # First 820 - NAT!  Very uniform noisy mostly under 2 MB/s\n",
    " '84.235.73.20', # First 821 - NAT!  Very uniform noisy mostly under 2 MB/s\n",
    " '84.235.73.21', # First 822 - NAT!  Very uniformflat and noisy mostly under 2 MB/s\n",
    " '84.235.75.18', # First 823 - NAT!  Very uniform noisy mostly under 2 MB/s\n",
    " '84.235.75.21', # First 824 - NAT!  Very uniform noisy mostly under 2 MB/s\n",
    "]\n",
    "\n",
    "if True:\n",
    "    CuratedBeacons = run_query(seriesQ, beacons=selectedBeaconQ, timeindex=None,\n",
    "                             beacon_fields=beacon_fields, roguesgallery=str(roguesgallery)[1:-1])\n",
    "    CuratedBeacons.index = pd.DatetimeIndex(CuratedBeacons['test_time']*1000000000)\n",
    "print 'Done'\n",
    "\n",
    "# print CuratedBeacons\n",
    "if True:\n",
    "    tmp = CuratedBeacons[CuratedBeacons['clientIP'] == '84.235.73.20']\n",
    "    new_plot_beacon_rates(tmp, title='Test of 84.235.73.20', figsize=(16, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display seleceted (Curated) beaconsnew_plot_beacon_rates\n",
    "\n",
    "if True:\n",
    "    # Force inline because interactive opens seperate windows for each\n",
    "    %matplotlib inline\n",
    "    tmp = pd.DataFrame(CuratedBeacons, copy=True)\n",
    "    pdata = tmp.pivot_table(index=tmp.index, columns='clientIP', values='rate')\n",
    "    print len(list(pdata))\n",
    "    for c, n in zip(list(pdata), range(len(pdata))):\n",
    "        print \"   '%s', # Selected %d\"%(c, n)\n",
    "        new_plot_beacon_rates(pdata, title=\"Client \"+c, clients=[c], figsize=(16, 3))\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Figures\n",
    "\n",
    "PaperDir = '../paper/'\n",
    "PaperDir = './'\n",
    "DoPaper = False\n",
    "if True:\n",
    "    ofile = None\n",
    "    if DoPaper:\n",
    "        ofile = PaperDir+'Selected.png'\n",
    "        print 'Formating to:', ofile\n",
    "    %matplotlib\n",
    "    tmp = pd.DataFrame(CuratedBeacons, copy=True)\n",
    "    # pdata = tmp.pivot_table(index=tmp.index, columns='clientIP', values='rate')\n",
    "    new_plot_beacon_rates(tmp[tmp['clientIP']=='217.72.93.226'],\n",
    "                  ofile=ofile, figsize=(6, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
